<html>
<head><title>Social Computing Symposium 2016-01-12</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script src="fragmention.js"></script>
<script src="hovercards.js"></script>
<link href="style.css" media="all" rel="stylesheet" type="text/css" />
<link rel="webmention" href="https://webmention.herokuapp.com/api/webmention" />
</head>
<body>
<article class="h-entry">
<h1 class="p-name">Social Computing Symposium <time class="dt-published">2016-01-12</time></h1>
<div class="e-content">

<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.katecrawford.net'>Kate Crawford</a>:  <blockquote class='e-content'><p>there is a huge growth of listening machines, from siri to cortana to google now
<p>I focus on the social and ethical implications of large data systems, and I find listening machines fascinating
<p>in 1650 the Jesuit Kirscher built the talking statue - a large shell in the wall that listens to the piazza
<p>the talking statue was designed as a kind of elite magic - only the elites knew it could exist
<p>listening machines have always been about power, about class and invisibility
<p>whats different now is that listening machines are becoming ubiquitous and have personalities
<p>all this recorded audio can provide a kind of time travel where you can go back through all people in your house
<p>Hello Barbie's guts are controlled by toytalk - they listen to children's questions and come up with new answers
<p>So Hello Barbie is the reverse of the talking statue - it listens in your house and sends it out to the public
<p>how we handle frendship requires forgetting - with perfect archives we can't do this
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://timhwang.org'>Tim Hwang</a>:  <blockquote class='e-content'><p>when does our interest in moderation conflict with our interest in privacy?
<p>this is basic panopticon design 101 - it serves notice that you are being watched
<p>so what is different from Leviathan? a platform implemented in code, and at a huge new scale
<p>code moderations implies persistent identities and persistent record of action for the code to run
<p>platforms have perverse incentives to maximise the EMO threshold - Engagement Maximising Outrage
<p>platforms see themselves as platforms as passive infrastructure - CDA 230 encourages hands-off on this
<p>the centre of gravity of commercial entities is that they will moderate less than we'd like them to 
<p>we could call for fragmentation - to have a variety of platforms that make different privacy/moderation tradeoffs
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.katecrawford.net'>Kate Crawford</a>:  <blockquote class='e-content'><p>the listening machine has now become a key driver for AI - Gate's machines that listen, see and understand
<p>understanding is still hard, but we are getting better at machines that can see and hear
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://timhwang.org'>Tim Hwang</a>:  <blockquote class='e-content'><p>a lot of deep learning and AI systems are very data-hungry processes - they need a lot to fulfil the promise
<p>I use listening to mean data collection, but it also implies comprehension—that's not up to human moderator standard
<p>the scale of these platforms make certain moderation systems difficult 
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.vivienneming.com'>Vivienne Ming</a>:  <blockquote class='e-content'><p>my wife and I developed a system for U Phoenix and found it had to happen within 11 minutes to be effective
<p>AI really ought to be Augmented Intelligence,  not Artificial Intelligence
<p>what we need is to signal to people thta they ned to intervene, but to respond fast they need to get the context
<p>there is a strong interest in protecting the privacy of people being harassed, but not the harassers
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href=''>q</a>:  <blockquote class='e-content'><p>What is the social contract? Is there something that we have defined as a society to protect people?
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://timhwang.org'>Tim Hwang</a>:  <blockquote class='e-content'><p>it becomes difficult to do this because of the perverse economics of scale
<p>the ability of users to switch to another platform may not be enough to force the platforms to the table
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.vivienneming.com'>Vivienne Ming</a>:  <blockquote class='e-content'><p>education should be about producing happy, healthy impactful lives - explicitly, measurably and soley
<p>we listened to 10,000 undergrads and 20,000 MBAs writings on the coursework discussion
<p>we designed a system that learned economics and biology by reading the students' writing, then predicted grades
<p>we were able to predict everyone's final score within 2% based on their writing on the discussion site
<p>a bachelors' degree in CS from Stanford was only a very modest predictor of your skill as a programmer
<p>we saw the same patterns of behaviour with skateboarders and with CEOs 
<p>cognitive ability and endogenous motivation were predictive of success
<p>endogenously motivated people vastly outperform exogenously people, yet we structure classrooms exogenously
<p>most sales for salespeople happen at end of cycle, but those who sell the 1st day of the cycle do better overall
<p> we monitored preschoolers to predict their life outcomes - we put 3 mics in the classroom to detect speakers
<p>however it is a cursed crystal ball - when you give people predictions of outcomes it reinforces the bad ones
<p>the people who need this reinforcement the most are the least likely to act on it
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.katecrawford.net'>Kate Crawford</a>:  <blockquote class='e-content'><p>the idea of predicting life outcomes worries me - attaching children to predictions change how teachers behave
<p>if I say "you're child is going to win a nobel prize" it makes it less likely to happen 
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.vivienneming.com'>Vivienne Ming</a>:  <blockquote class='e-content'><p>the things I am talking about ought to scare people
<p>people can change direction - I know I did; I don't want predictions to come true, but to change them
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://vivatropolis.com/judith/'>Judith Donath</a>:  <blockquote class='e-content'><p>what if you didn't do the surveillance of kids and sent universally applicable messages to parents instead?
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://geomblog.blogspot.com'>Suresh Venkat</a>:  <blockquote class='e-content'><p>I am a computer scientist and I study algorithms. sometimes they learn patterns
<p>the same algorithm that tells me I should buy the new star wars box set, could be used to deny me a loan
<p>Algorithms make mistakes, and make mistakes that are hard to discover in high dimensional spaces
<p>when a camera thinks that you have blinked, but you are asian and that is how your eyes look
<p>when google decides that your name implies that you need ads for bail bonds, that is a problem
<p>a machine learning algorithm is a recipe for making recipes, which means you can't know how it made its decision
<p>you can't inspect and debug learned algorithms as they don't justify their parameters
<p>can we detect if algorithms discriminate against minority groups? Have the been trained on unfair data?
<p>can we express fairness and justice in such a way that algorithms can learn to be fair?
<p>we want algorithms to be reasonable and logical like Spock, but overuled by the emotional Kirk
<p>now algorithms are like 2-year-olds; the're inscrutable and you don't want them to have control, but they may grow up
<p>even if you have a good algorithm the training data and the evaluation metrics can cause bias
<p>if the algorithm has a small training set of eg women in tech jobs, it can discriminate against them
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.vivienneming.com'>Vivienne Ming</a>:  <blockquote class='e-content'><p>a recruiter will look at your name, your university and your job title at the last job—we look at 50k datapoints
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://geomblog.blogspot.com'>Suresh Venkat</a>:  <blockquote class='e-content'><p>we are not saying you should not use algorithms, but understand how they introduce bias
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://tilde.club/~tim'>Tim Carmody</a>:  <blockquote class='e-content'><p>the social contract is being replaced by the terms on service and this sets the new ideology
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://geomblog.blogspot.com'>Suresh Venkat</a>:  <blockquote class='e-content'><p>what we're seeing is the same old story expressed on a different platform - who has power?
<p>we're seeing the same kind of amplification that happened with the printing press
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.denniscrowley.com'>Dennis Crowley</a>:  <blockquote class='e-content'><p>I went to kate's listening machines summit last summer, and I want to talk about what we're doing at foursquare
<p>we're doing listening, but not to audio, but to where phones go - where did you walk to, how long were you there
<p>we're tryign to work out the magical things we can do with that
<p>we sell some of the data, we sell some advertising, but what can we work out from this data? what should we do?
<p>I want to make software like Scarlett Johansen's character in Her that whispers to you occasionally
<p>what if you are walking down the street and it says "see that place? you should go there sometime"
<p>or when you walk into the bar it whispers "3 people you like and one you don't are here already"
<p>so many of these things you ask a question and it come to your aid when summoned - it can't suggest
<p>what if the software could summon you and say Dennis, when you leave ITP you should go to this place
<p>what if it could suggest a detour while you are walking home to an interesting store in the next street?
<p>we have an opportunity to break people out of their habits - not just reactive systems
<p>software could spot downtime and suggest detours
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.latoyapeterson.com/'>Latoya Peterson</a>:  <blockquote class='e-content'><p>how come we always frame things as algorithms making things better? when the biases are irrational
<p>why do we think we can apply rational solutions to fixing irrational responses?
<p>there is this idea that more, better cleaner data will fix things
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://geomblog.blogspot.com'>Suresh Venkat</a>:  <blockquote class='e-content'><p>cleaner data may fix it, but we have the bad and dirty data that gets reinforced by the algorithms
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.vivienneming.com'>Vivienne Ming</a>:  <blockquote class='e-content'><p>if your data is talking to you you should see a doctor - you ask questions and get answers
<p>you think your dashboard is giving you answers, but it is just a bunch of bargraphs inspect questions
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://kevinmarks.com'>Kevin Marks</a>:  <blockquote class='e-content'><p>If you ask a person to justify a decision they will confabulate an answer to justify it
<p>I'm worried that machines will be coded to confabulate plausible arguments too
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://tigoe.net'>Tom Igoe</a>:  <blockquote class='e-content'><p>there are times when I don't trust foursquare, because it don't know when there is data that shoudl be just between us
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://research.microsoft.com/en-us/people/lilich/'>Lili Cheng</a>:  <blockquote class='e-content'><p>what would you send people when they are walking to work, could you send random ones? look left
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://www.denniscrowley.com'>Dennis Crowley</a>:  <blockquote class='e-content'><p>what if you could make the software be flirty "I was just thinking about you - you should go to this place…"
<p>we were trying to get people feel less freaked out about the algorithm knowing about us
<p></blockquote></div>
<div class='h-cite'><a class='h-card p-category' href='http://vivatropolis.com/judith/'>Judith Donath</a>:  <blockquote class='e-content'><p>I want to talk about trust and cute machines that want us to trust them
<p>in 1950 Turing wrote a paper <a class="auto-link" href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf">http://www.csee.umbc.edu/courses/471/papers/turing.pdf</a> that suggested machines should talk like humans
<p>Weizenbaum in 1964 made Eliza that could hold a conversation by asking questions
<p>He hoped that people would see that this was not AI, but instead people did trust it 
<p>Weizenbaum gave up programming and wrote a novel warning of technology built by people what don't understand social
<p>I gave a talk to a group of psychoanalysts and they were and audience that really paid attention and listened well
<p>how many of you have worked as a waitress, where you have to fake emotion?
<p>would you want to know what they really think of you?
<p>this is an artificial seal that is a cuddly toy, but it can behave like an animal, curling up and responding
<p>people with dementia are improved by contact with animals, but can't care for one—using an animated toy works for them
<p>a tamagotchi was and electronic pet that you had to pay attention to, or it would die
<p>the japanese tamagotchi would actually die, and not come back if neglected. The US one you could reset
<p>if you're 3 then the world is a big psychedelic trip anyway, but when toys start actually talking that changes things
<p>there was a russian experiment where they bred wolves for good personality, and it also gave them neonatal features
<p>instead of using instructions to help us work tech, we make them look like babies so we take care of them
<p>Hello Barbie is the deep sea angler fish of technology
<p>by morphing your face with a political candidate's face you make the candidate more attractive to you
</blockquote></div>
</div>
</article>
<script id="webmention-hosted">
  (function () {
    var sn = document.createElement("script"), s = document.getElementsByTagName("script")[0], url;
    url = document.querySelectorAll ? document.querySelectorAll("link[rel~=canonical]") : false;
    url = url && url[0] ? url[0].href : false;
    sn.type = "text/javascript"; sn.async = true;
    sn.src = "//webmention.herokuapp.com/api/embed?version=cutting-edge&url=" + encodeURIComponent(url || window.location);
    s.parentNode.insertBefore(sn, s);
  }());
</script>

</body>
</html>